
#include<stdio.h>
#include<stdlib.h>
#include<unistd.h>
#include<stdbool.h>
#include<time.h>
#include<mpi.h>
#include<string.h>
#include<math.h>
#include "/content/clockcycle.h"
#define Genes 7129     // X Total Number of genes to be given as an input. 
#define Samples 34          // Represents the sample genes
//Change the value of K to obtain the results with different clusters
#define K 5 // Number of clusters
//Initializations
int *cluster_idx;             
double *gene_data;          
double *medoids;   					 // pointer to data  which stores the index of the centroid nearest to each pixel


//Define a macro to compute the minimum
#ifndef MIN1
#define MIN1(x, y) ((x < y) ? 1: 0)
#endif


//Macro
#ifndef MIN
#define MIN(x, y) ((x < y) ? x : y)
#endif

//Macro to compute the maximum
#ifndef MAX
#define MAX(x, y) ((x < y) ? y : x)
#endif


/*INFINITY is a macro constant defined in the <math.h> library, and we use it to perform mathematical comparisons*/
#ifdef INFINITY
/* INFINITY is supported */
#endif




//Finding the closeset medoids
void findclosestmedoids(double *num, double *medoids, int *idx, int rank, int size,int process_job, int si,int ei) {
    int i, j, l, for_i;
    double sum, dist[K], min_dist, local_min_dist;




    // Broadcast the medoids to all processes
    MPI_Bcast(medoids, K * Samples, MPI_DOUBLE, 0, MPI_COMM_WORLD);

    // Find the closest medoid for each local data point
    for (for_i = 0; for_i <process_job; for_i++) {
        i = si + for_i;
        local_min_dist = INFINITY;

        for (j = 0; j < K; j++) {
            sum = 0;

            for (l = 0; l < Samples; l++) {
             
                sum += fabs(num[i * Samples + l] - medoids[j * Samples + l]);
            }

            dist[j] = sum;

            if (MIN1(dist[j],local_min_dist)) {
                local_min_dist = dist[j];
                idx[i] = j;
            }
        }
    }



    // Reduce the local min distances to find the global min distance
    //The reason why we use
    MPI_Allreduce(&local_min_dist, &min_dist, 1, MPI_DOUBLE, MPI_MIN, MPI_COMM_WORLD);

    // Update the indices for data points with the global min distance
    for (i = si; i < ei; i++) {
        if (dist[idx[i]] == min_dist) {
            idx[i] = j;
        }
    }
}






int main(int argc, char *argv[]){



// All variables definitions
    int myrank, numranks, result;
    int i,j,k;
    int process_job, each_chunk_pos;
    double starttime, endtime;
  
      MPI_Init(NULL, NULL);
      MPI_Status status;
      MPI_Request r_request, s_request;

      int world_size;
      MPI_Comm_size(MPI_COMM_WORLD, &world_size);

      int world_rank;
      MPI_Comm_rank(MPI_COMM_WORLD, &world_rank);

    int rnd_num;
    int n =Genes, fs = Samples, k1=K, *label,lab;
    MPI_Request request1, request2, request3, request4; 
    
      MPI_File fh,fh1;
      int si,ei;

    
        //Determination of each chunk of the input file each process is going to read
//This is nothing but the buffer with  filesize/number of processes. The idea is also taken from slide 11

  process_job=Genes/world_size;
 


	if(world_rank==world_size-1)
  {
		process_job=process_job+Genes%world_size;
  }

  


    gene_data = (double*) calloc(Genes * Samples, sizeof(double));
    medoids = (double*) calloc(K * Samples, sizeof(double));
    cluster_idx = (int*) calloc(Genes, sizeof(int));



	
  

  // This is taken from slide number 11 of MPI file I/O that uses MPI I/O to read from the input file.

//We also experimented with bin format of the file. However, txt is also faster. 


  result=MPI_File_open(MPI_COMM_WORLD, "training.txt", MPI_MODE_RDONLY, MPI_INFO_NULL, &fh);
  		if(result != MPI_SUCCESS) {printf("Error in opening the file\n"); exit(-1);}
  result=MPI_File_read_at(fh, world_rank*process_job*Samples*sizeof(double),gene_data,process_job*Samples, MPI_INT, &status);
  	if(result != MPI_SUCCESS) {printf("Error in reading the file\n"); exit(-1);}
  MPI_File_close(&fh);



	MPI_Barrier(MPI_COMM_WORLD);
	MPI_File_close(&fh);







	if (world_rank==0)
	{	
    // Let us start calculation of time
                starttime = clock_now();
	 int lower =0;
		int upper =process_job-1;
		srand(time(0));

  
  
    

		for (int i = 0; i < K; i++) {

			int rnd_num = (rand()%(upper-lower + 1)) + lower;
	
		
			for (j=0;j<Samples;j++){ 
        		*(medoids+i*Samples+j) = *(gene_data+rnd_num*Samples+j); 
        	} 
      
    }
  
  }

   
 

    si = (world_rank)*(Genes/world_size);

    if(world_rank==(world_size-1))
    {
        ei = Genes;
    }
    else
    {
        ei = (world_rank+1)*(Genes/world_size);
    }

    
 /*We run the findclosestmedoids for 10 iterations. 
 The broadcast to all the processes and also the computation of final result using MPI_Allreduce is done in
 the function itself. Therefore we do not do it here. */


      for (i=0;i<10;i++){

        findclosestmedoids((double *)gene_data, (double *)medoids, &cluster_idx[0],
        world_rank,process_job,world_size,si,ei);
        MPI_Barrier(MPI_COMM_WORLD);
    for (int a=0; a<K;a++){
        
          for (int b=0;b<Samples;b++){

            *(medoids+a*Samples+b)=*(medoids+a*Samples+b)/world_size;
          }
        }
      

      }
      

  //Print on the console the medoids that are computed
    if(!world_rank)
      for (i=0; i<K;i++){
      
      for (k=0;k<Samples;k++){

      printf ("Medoids   %e \t ", *(medoids+i*Samples+k)/world_size);
      }
      printf("\n");
    }





   endtime = clock_now();


        if (world_rank== 0) {
               
         
           printf("Total time taken to run K-Medoids on %d Genes with %d clusters is %lf seconds.\n", Genes, K, (endtime-starttime)/512000000.0f);
           }
     


//Here we have to write using MPI File I/O


    MPI_Barrier(MPI_COMM_WORLD);
    MPI_File_close(&fh1);

      MPI_Finalize();
      free(gene_data);
      free(medoids);

      free(cluster_idx);
    return 0;
}
